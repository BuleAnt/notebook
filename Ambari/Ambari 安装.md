# Ambari 安装



选择HDP-2.6版本

本地库

http://nexus.metaapp.org/repository/yum-hdp-2.6.5.0/

http://nexus.metaapp.org/repository/yum-hdp-gpl-2.6.5.0/

http://nexus.metaapp.org/repository/yum-hdp-utils-1.1.0.22/



Mysql-connector

http://www.java2s.com/Code/JarDownload/mysql/mysql-connector-java.jar.zip



设置mysql 数据库连接

```
ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java-8.0.12.jar
```



/usr/share/java/mysql-connector-java.jar

```

[root@ambari ~]# ambari-server setup
Using python  /usr/bin/python
Setup ambari-server
Checking SELinux...
SELinux status is 'enabled'
SELinux mode is 'permissive'
WARNING: SELinux is set to 'permissive' mode and temporarily disabled.
OK to continue [y/n] (y)? 

Customize user account for ambari-server daemon [y/n] (n)? 

```

```
hostnamectl set-hostname hadoop8.bigdata.org

cat > /etc/resolv.conf <<EOF
# Generated by NetworkManager
search bigdata.org
nameserver 172.16.17.140
EOF

ping hadoop1.bigdata.org

-------------------------
vim /etc/resolv.conf
nameserver 172.16.17.140

cd /etc/yum.repos.d/
wget https://dns.metaapp.org/repos/ambari.repo --no-check-certificate

# 所有节点安装
yum install ambari-agent -y 
systemctl enable ambari-agent 
systemctl restart ambari-agent && systemctl status ambari-agent
```

密钥安装

```
# 在主节点生成密钥匙

hostnamectl set-hostname hadoop7.bigdata.org
    ssh-keygen -t rsa

# 生成 秘钥后分发

cd .ssh
id_rsa

    ssh-copy-id -i ~/.ssh/id_rsa.pub root@172.16.16.35

#
/root/.ssh/id_rsa.pub

# 这样主节点 就可以免密访问所有节点
## 所有节点之间能够相互访问，
##  1、在每个节点上 向主节点分发秘钥。
	2、在主节点 将 authorized_keys 分发给所有节点，完成节点之间的免密登录
	3、known_hosts 分发效果会更好。


```

ambari-agent 安装

```


# 安装ambari-agent
yum install ambari-agent*

# vim /etc/ambari-agent/conf/ambari-agent.ini ,确保[server]部分下的hostname指向实际的Ambari Server主机，而不是“localhost”。
...
[server]
hostname=localhost
 
...

# 启动服务
ambari-agent start
```



安装java

```

cat << EOF >> /etc/profile
export JAVA_HOME=/usr/jdk64/jdk1.8.0_112
export CLASS_PATH=$JAVA_HOME/lib:$JAVA_HOME/jre/lib
export PATH=$JAVA_HOME/bin:$PATH
EOF

source /etc/profile

```





关掉防火墙

```
firewall-cmd --state
systemctl disable firewalld.service 
systemctl stop firewalld.service


=========
systemctl status iptables
systemctl disable iptables.service 
systemctl stop iptables.service 
systemctl status iptables

```

1、firewalld的基本使用

```
启动： systemctl start firewalld
关闭： systemctl stop firewalld
查看状态： systemctl status firewalld 
开机禁用  ： systemctl disable firewalld
开机启用  ： systemctl enable firewalld

```



关闭SElinux

```
vi /etc/sysconfig/selinux
SELINUX=disabled
```





创建数据库

```
172.16.16.21
ZHvfH6tXim-
root
ALTER USER 'root'@'localhost' IDENTIFIED BY 'K7kl32da4o2d-';
update user set authentication_string=password('K7kl32da4o2d-') where user='root';
SET PASSWORD = PASSWORD('K7kl32da4o2d-');

ranger
CREATE DATABASE IF NOT EXISTS ranger default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'rangeradmin'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON ranger.* TO 'rangeradmin'@'%';

rangerkms
CREATE DATABASE IF NOT EXISTS rangerkms default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'rangerkms'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON rangerkms.* TO 'rangerkms'@'%';


superset
CREATE DATABASE IF NOT EXISTS superset default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'superset'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON superset.* TO 'superset'@'%';

hive
CREATE DATABASE IF NOT EXISTS hive default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'hive'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON hive.* TO 'hive'@'%';

druid
CREATE DATABASE IF NOT EXISTS druid default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'druid'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON druid.* TO 'druid'@'%';

oozie
CREATE DATABASE IF NOT EXISTS oozie default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'oozie'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON oozie.* TO 'oozie'@'%';


ambari
CREATE DATABASE IF NOT EXISTS ambari default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'ambari'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON ambari.* TO 'ambari'@'%';

azkaban
CREATE DATABASE IF NOT EXISTS ambari default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'azkaban'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON azkaban.* TO 'azkaban'@'%';

meta
CREATE USER 'meta'@'%' IDENTIFIED BY 'K7kl32da4o2d-';
GRANT all ON *.* TO 'meta'@'%';




appdata
CREATE DATABASE IF NOT EXISTS appdata default charset utf8 COLLATE utf8_general_ci;

CREATE USER 'appdata'@'%' IDENTIFIED BY 'KVdawj08kna-';
GRANT all ON appdata.* TO 'appdata'@'%';
```





```
/var/log/hadoop
/hadoop/hdfs/data
/hadoop/hdfs/namenode

yum
/hadoop/yarn/log
/app-logs
/var/log/hadoop-yarn

/var/log/hadoop-mapreduce
/var/log/hive
/tmp/hive/operation_logs
/var/log/hbase
/var/log/oozie
/var/log/zookeeper
/var/log/storm
/var/log/accumulo
/var/log/ambari-infra-solr-client
/var/log/ambari-infra-solr
/var/log/ambari-metrics-monitor
/var/log/ambari-metrics-collector
/var/log/ambari-metrics-grafana
/var/log/ambari-metrics-collector
/var/log/atlas
/var/log/kafka
/var/run/knox
/var/log/ambari-logsearch-portal
/var/log/ambari-logsearch-logfeeder
/var/log/ranger/usersync
/var/log/ranger/tagsync
/var/log/ranger/kms
/var/log/livy2
/var/log/spark2
/var/log/zeppelin
```



用户

```
Users/Groups	Usernames
Smoke User	

ambari-qa
Hadoop Group	

hadoop
Accumulo User	

accumulo
Infra Solr User	

infra-solr
Ambari Metrics User	

ams
Metadata User	

atlas
Druid User	

druid
HBase User	

hbase
HDFS User	

hdfs
Proxy User Group	

users
Hive User	

hive
Kafka User	

kafka
Knox Group	

knox
Knox User	

knox
Log Search User	

logsearch
Mapreduce User	

mapred
Oozie User	

oozie
Ranger Group	

ranger
Ranger User	

ranger
Kms Group	

kms
Kms User	

kms
Livy2 Group	

livy
Livy2 User	

livy
Spark2 Group	

spark
Spark2 User	

spark
Sqoop User	

sqoop
Storm User	

storm
Superset User	

superset
Tez User	

tez
Yarn ATS User	

yarn-ats
Yarn User	

yarn
Zeppelin Group	

zeppelin
Zeppelin User	

zeppelin
ZooKeeper User	

zookeeper

```

```
The cluster consists of 3 hosts
3 warnings
Master services installed
SNameNode installed on hadoop2.bigdata.org
NameNode installed on hadoop1.bigdata.org
ResourceManager installed on hadoop1.bigdata.org
History Server installed on hadoop2.bigdata.org
HiveServer2 installed on hadoop2.bigdata.org
HBase Master installed on hadoop1.bigdata.org
Oozie Server installed on hadoop1.bigdata.org
```



安装完成后，服务无法启动：修复问题

```
HDFS

```





终于在参考别人的blog之后，找到命令删除的方式



\1. 查询资源

```sql
curl -u admin:admin -H “X-Requested-By: ambari” -X GET http://10.21.23.29:8080/api/v1/clusters/beta_eu/services/
```



\2. 删除资源

```sql
curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE http://10.21.23.29:8080/api/v1/clusters/beta_eu/services/KAFKA
```



\3. 如果删除失败，先stop在删除

```sql
#curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE http://10.21.23.29:8080/api/v1/clusters/beta_eu/services/APPCONFIGURATION
{
  "status" : 500,
  "message" : "org.apache.ambari.server.controller.spi.SystemException: An internal system exception occurred: Cannot remove beta_eu/APPCONFIGURATION. One or more host components are in a non-removable state."
```



\4. 停止service

```sql
[root@ip-10-21-23-29 ~]#  curl -u admin:admin -H "X-Requested-By: ambari" -X PUT -d '{"RequestInfo":{"context":"Stop Service"},"Body":{"ServiceInfo":{"state":"INSTALLED"}}}' 10.21.23.29:8080/api/v1/clusters/beta_eu/services/APPCONFIGURATION
{  "href" : "http://10.21.23.29:8080/api/v1/clusters/beta_eu/requests/24",
  "Requests" : {
    "id" : 24,
    "status" : "Accepted"  }
```



\5. 删除service

```sql
[root@ip-10-21-23-29 ~]#curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE http://10.21.23.29:8080/api/v1/clusters/beta_eu/services/APPCONFIGURATION
```



\6. 再次检查，已经没有service了

```sql
[root@ip-10-21-23-29 ~]#  curl -u admin:admin -H “X-Requested-By: ambari” -X GET http://10.21.23.29:8080/api/v1/clusters/beta_eu/services/
curl: (6) Couldn't resolve host 'ambari”'
{
  "href" : "http://10.21.23.29:8080/api/v1/clusters/beta_eu/services/",
  "items" : [ ]
```





参考链接

http://blog.csdn.net/chengyuqiang/article/details/61195805





停掉Ambari 集群[有问题]

 清除ambari中旧的集群，只需要停掉ambari-server服务，用ambari-server reset命令重置ambari数据库



- 删除节点所有的软件

  ```
  yum remove `yum list | grep @HDP | awk '{print $1}'` -y
  
  ```




获取集群页面

http://ambari.bigdata.org:8080/views/ADMIN_VIEW/2.7.0.0/INSTANCE/#/clusterInformation



防火墙

```
firewall-cmd --state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）
[root@localhost ~]#firewall-cmd --state
not running


systemctl stop firewalld.service #停止firewall
systemctl disable firewalld.service #禁止firewall开机启动
```



```

```

----------------



卸载 ambari

```
yum remove -y  sqoop.noarch
yum remove -y  lzo-devel.x86_64
yum remove -y  hadoop-libhdfs.x86_64
yum remove -y  rrdtool.x86_64
yum remove -y  hbase.noarch
yum remove -y  pig.noarch
yum remove -y  lzo.x86_64
yum remove -y  ambari-log4j.noarch
yum remove -y  oozie.noarch
yum remove -y  oozie-client.noarch
yum remove -y  gweb.noarch
yum remove -y  snappy-devel.x86_64
yum remove -y  hcatalog.noarch
yum remove -y  python-rrdtool.x86_64
yum remove -y  nagios.x86_64
yum remove -y  webhcat-tar-pig.noarch
yum remove -y  snappy.x86_64
yum remove -y  libconfuse.x86_64
yum remove -y  webhcat-tar-hive.noarch
yum remove -y  ganglia-gmetad.x86_64
yum remove -y  extjs.noarch
yum remove -y  hive.noarch
yum remove -y  hadoop-lzo.x86_64
yum remove -y  hadoop-lzo-native.x86_64
yum remove -y  hadoop-native.x86_64
yum remove -y  hadoop-pipes.x86_64
yum remove -y  nagios-plugins.x86_64
yum remove -y  hadoop.x86_64
yum remove -y  zookeeper.noarch  
yum remove -y  hadoop-sbin.x86_64
yum remove -y  ganglia-gmond.x86_64
yum remove -y  libganglia.x86_64
yum remove -y  perl-rrdtool.x86_64
yum remove -y  epel-release.noarch
yum remove -y  compat-readline5*
yum remove -y  fping.x86_64
yum remove -y  perl-Crypt-DES.x86_64
yum remove -y  exim.x86_64
yum remove -y ganglia-web.noarch
yum remove -y perl-Digest-HMAC.noarch
yum remove -y perl-Digest-SHA1.x86_64
yum remove -y bigtop-jsvc.x86_64
yum remove -y oozie*
yum remove -y oozie*

cd $alterNativesDir
rm -rf hadoop-etc
rm -rf zookeeper-conf
rm -rf hbase-conf
rm -rf hadoop-log
rm -rf hadoop-lib
rm -rf hadoop-default
rm -rf oozie-conf
rm -rf hcatalog-conf
rm -rf hive-conf
rm -rf hadoop-man
rm -rf sqoop-conf
rm -rf hadoop-confone

userdel -rf nagios
userdel -rf hive
userdel -rf ambari-qa
userdel -rf hbase
userdel -rf oozie
userdel -rf hcat
userdel -rf mapred
userdel -rf rrdcached
userdel -rf zookeeper
userdel -rf sqoop
userdel -rf puppet
userdel -rf flume
userdel -rf tez
userdel -rf yarn
userdel -rf activity_analyzer
userdel -rf ams  
userdel -rf infra-solr  
userdel -rf logsearch
userdel -rf kms  
userdel -rf livy  
userdel -rf ranger  
userdel -rf roo  
userdel -rf spark  
userdel -rf yarn-ats  
userdel -rf zeppelin


rm -rf /hadoop
rm -rf /etc/hadoop
rm -rf /etc/hbase
rm -rf /etc/hcatalog
rm -rf /etc/hive
rm -rf /etc/ganglia
rm -rf /etc/nagios
rm -rf /etc/oozie
rm -rf /etc/sqoop
rm -rf /etc/zookeeper
rm -rf /var/run/hadoop
rm -rf /var/run/hbase
rm -rf /var/run/hive
rm -rf /var/run/ganglia
rm -rf /var/run/nagios
rm -rf /var/run/oozie
rm -rf /var/run/zookeeper
rm -rf /var/log/hadoop
rm -rf /var/log/hbase
rm -rf /var/log/hive
rm -rf /var/log/nagios
rm -rf /var/log/oozie
rm -rf /var/log/zookeeper
rm -rf /usr/lib/hadoop
rm -rf /usr/lib/hbase
rm -rf /usr/lib/hcatalog
rm -rf /usr/lib/hive
rm -rf /usr/lib/oozie
rm -rf /usr/lib/sqoop
rm -rf /usr/lib/zookeeper
rm -rf /var/lib/hive
rm -rf /var/lib/ganglia
rm -rf /var/lib/oozie
rm -rf /var/lib/zookeeper
rm -rf /var/tmp/oozie
rm -rf /tmp/hive
rm -rf /tmp/nagios
rm -rf /tmp/ambari-qa
rm -rf /tmp/sqoop-ambari-qa
rm -rf /var/nagios
rm -rf /hadoop/oozie
rm -rf /hadoop/zookeeper
rm -rf /hadoop/mapred
rm -rf /hadoop/hdfs
rm -rf /tmp/hadoop-hive
rm -rf /tmp/hadoop-nagios
rm -rf /tmp/hadoop-hcat
rm -rf /tmp/hadoop-ambari-qa
rm -rf /tmp/hsperfdata_hbase
rm -rf /tmp/hsperfdata_hive
rm -rf /tmp/hsperfdata_nagios
rm -rf /tmp/hsperfdata_oozie
rm -rf /tmp/hsperfdata_zookeeper
rm -rf /tmp/hsperfdata_mapred
rm -rf /tmp/hsperfdata_hdfs
rm -rf /tmp/hsperfdata_hcat
rm -rf /tmp/hsperfdata_ambari-qa

yum remove -y ambari-*
yum remove -y zook*
yum remove -y postgresql
rm -rf /var/lib/ambari*
rm -rf /var/log/ambari*
rm -rf /etc/ambari*

yum -y remove smartsense-hst
yum -y install smartsense-hst

rm -rf /usr/hdp
rm -rf /bin/zookeeper*
rm -rf /etc/yum.repos.d/ambari*
```



### 重装 ambari

```
yum -y remove smartsense-hst
yum -y install smartsense-hst
```



```
docker run --name zabbix-server-mysql -t \
      -e DB_SERVER_HOST="database.bigdata.org" \
      -e MYSQL_DATABASE="zabbix" \
      -e MYSQL_USER="zabbix" \
      -e MYSQL_PASSWORD="K7kl32da4o2d-" \
      -e MYSQL_ROOT_PASSWORD="K7kl32da4o2d-" \
      -e ZBX_JAVAGATEWAY="zabbix-java-gateway" \
      --link zabbix-java-gateway:zabbix-java-gateway \
      -p 10051:10051 \
      -d zabbix/zabbix-server-mysql:latest

docker run --name zabbix-web-nginx-mysql -t \
      -e DB_SERVER_HOST="database.bigdata.org" \
      -e MYSQL_DATABASE="zabbix" \
      -e MYSQL_USER="zabbix" \
      -e MYSQL_PASSWORD="K7kl32da4o2d-" \
      -e MYSQL_ROOT_PASSWORD="K7kl32da4o2d-" \
      --link zabbix-server-mysql:zabbix-server \
      -p 80:80 \
      -d zabbix/zabbix-web-nginx-mysql:latest


      GRANT all ON *.* TO 'root'@'%';
      GRANT ALL PRIVILEGES ON *.* TO 'root'@'172.16.17.131' IDENTIFIED BY 'K7kl32da4o2d-' WITH GRANT OPTION;
```

![image-20190118133517725](/Users/weicheng/Library/Application Support/typora-user-images/image-20190118133517725.png)

![image-20190118133705044](/Users/weicheng/Library/Application Support/typora-user-images/image-20190118133705044.png)









设置安全模式

```
sudo su hdfs -l -c'hdfs dfsadmin -safemode enter'
```

1. 登录NameNode主机**hadoop20.bigdata.org**。

2. 将NameNode置于安全模式（只读模式）：

   sudo su hdfs -l -c'hdfs dfsadmin -safemode enter'

3. 进入安全模式后，创建一个检查点：

   sudo su hdfs -l -c'hdfs dfsadmin -saveNamespace'

4. 一旦Ambari检测到NameNode处于安全模式并且检查点已成功创建，您就可以继续。

Safe mode is ON



#### 需要手动步骤：初始化JournalNodes

1. 登录NameNode主机**hadoop20.bigdata.org**。

2. 通过运行以下命令初始化JournalNodes：

   sudo su hdfs -l -c'hdfs namenode -initializeSharedEdits'

3. 一旦Ambari检测到JournalNodes已成功初始化，您就可以继续。



#### 需要手动步骤：初始化NameNode HA元数据

1. 登录NameNode主机**hadoop20.bigdata.org**。

2. 通过运行以下命令初始化NameNode自动故障转移的元数据：

   sudo su hdfs -l -c'hdfs zkfc -formatZK'

3. 登录其他NameNode主机

   hadoop21.bigdata.org

   。

   **重要！**请务必登录Additional NameNode主机。
   这是与上面的步骤1和2不同的主机。

4. 通过运行以下命令初始化Additional NameNode的元数据：

   sudo su hdfs -l -c'hdfs namenode -bootstrapStandby'



 步骤 1     执行命令退出安全模式：hadoop dfsadmin -safemode leave

 步骤 2     执行健康检查，删除损坏掉的block。  hdfs fsck  /  -delete



```
	已启用透明大页面压缩，可能会导致重大性能问题。请运行“echo never > /sys/kernel/mm/transparent_hugepage/defrag”和“echo never > /sys/kernel/mm/transparent_hugepage/enabled”以禁用此设置，然后将同一命令添加到 /etc/rc.local 等初始化脚本中，以便在系统重启时予以设置。以下主机将受到影响: 
```





Shuffle  分析

![image-20190524171938649](/Users/weicheng/Library/Application Support/typora-user-images/image-20190524171938649.png)

