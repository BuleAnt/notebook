## Hadoop的I/O操作

#### HDFS的数据完整性

HDFS会对写入的所有数据计算校验和，并在读取数据时验证校验和。

**datanode** 负责收到数据后在存储该数据及其校验和之前对数据进行验证。它在收到客户端的数据或复制其他datanode 的数据时执行这个操作。

客户端从 **datanode**读取数据时，也会验证校验和，并与datanode中存储的校验和进行对比。客户端成功验证一个数据块后，就会通知这个datanode，更新这个数据块的日志信息。



#### 压缩

文件压缩的好处：减少存储文件所需要的磁盘空间，加速数据在网络和磁盘上的传输。

与Hadoop 结合使用的常见压缩方法。

![image-20190301104149708](/Users/weicheng/Library/Application Support/typora-user-images/image-20190301104149708.png)

所有压缩算法都需要权衡空间/时间：压缩和解压缩速度更快，其代价通常只能节省少量的空间。

gzip是一个通用的压缩工具，在空间/时间性能的权衡中，居于其他两个算法之间。

bzip2 的压缩能力要强于gzip, 但压缩速度要慢一些。

LZO、LZ4 和 Snappy 均优化压缩速度， 速度比 gzip 快一个数量级，但压缩能力差些。



#### 压缩和输入分片

在考虑如何压缩将由MapReduce 处理的数据时，理解这些压缩格式是否支持切分(splitting)是非常重要的。以一个存储在HDFS文件系统中且压缩前大小为1GB的文件为例，HDFS块大小设置为128MB，那么该文件被存储在8个块中，将这个文件作为输入数据的MapReduce作业，将创建8个输入分片，其中的每个分片作为一个单独的map任务的输入被独立处理。

​        如果文件是经过gizp 压缩的，将没过数据块单独作为一个输入分片是无法实现工作的，因为无法实现从gizp 压缩数据流的任意位置读取数据。



#### 压缩格式建议

- 使用容器文件格式：顺序文件、Avro数据文件、ORCFiles、Parquet 文件，这些文件都同时支持压缩和切分，最好与一个快速压缩工具联合使用。例如。LZO，LZ4，或者Snappy
- 使用支持切分的压缩格式，例如bzip2(bzip2非常慢)，或者 使用索引实现切分的压缩格式 ，如LZO
- 在应用中将文件切分成块，并使用任意一种压缩格式为每个数据块建立压缩文件，这种情况下，需要合理选择数据块的大小，以确保压缩后的数据块的大小接近于HDFS块的大小。

对于大文件来说，不要使用不支持切分整个文件的压缩格式，因为会失去数据的本地特性，造成应用效率低



#### 序列化与反序列化





























