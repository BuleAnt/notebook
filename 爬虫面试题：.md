爬虫面试题：

选择题

1、以下所列出的方法中，浏览器web数据抓取效率最高的方法是？

A. selenium + phantomjs

B. 使用chrome或者chrome内核抓取

C. 模拟web协议直接用wget或curl抓取

 

2、下面哪项是手机端抓取app数据相比web端的优势（**多选**）：

A. 手机端协议简单容易分析

B. 手机端可以使用模拟点击

C. 手机端就算出新版了旧版还是可以继续使用，不会立即停掉

D. 通常来说，手机端抓取同样信息量的数据，下载量更低



3、下面代码请求实际访问地址url是什么？ 

 url = "https://test.cn/test"

params = {

   "xxxx":"1234"

}

headers = {

   "Host": "www.test.cn",

   "Accept-Encoding": "gzip,deflate",

   "Connection": "Keep-Alive"

}

requests.get(url, params, headers =headers, allow_redirects = False, verify = False)

假设http://test.cn/test?xxxx=1234返回的状态码302且response header里有Location:http://www.test.cn/dpool/ttt/domain.php?d=test&xxxx=1234

​    A.  https://test.cn/test

​    B.  https://test.cn/test?xxxx=1234

​    C.  https://www.test.cn/test?xxxx=1234

​    D. http://www.test.cn/dpool/ttt/domain.php?d=test&xxxx=1234

4、现在很多app采用了证书锁定ssl pinning来防止中间人攻击，关于ssl pinning下列说法错误的是：

​    A.  ssl pinning是将服务端证书打包内置到移动客户端中，HTTPS连接建立时与服务端返回的证书对比一致性，以确定这个连接的合法性

​    B.  采用ssl pinning的app，仍然可以直接使用mitm proxy，fiddler等抓包工具可获取到明文包

​    C.  使用frida等工具绕过证书锁定后，抓包工具才能获取到明文HTTPS数据包

​    D.  采用了ssl pinning证书锁定的app，内置证书一般为自签名证书



解答题

1、请分别简述 请求包体(Request)，响应包体(Response)的构成.









2、编写xpath 提取 div元素下的文字内容


	<!-- 要提取内容的HTML  -->
	<div class="gamesIntroText">
	  <div class="details" style="display:block;">
		<p>《xxxx》是一款为大家提供了超多便利交友过程的平台!</p>
		<p>《xxx》介绍</p>
		<div><p>单身的你，或是想寻找生命中的那个TA，或是想认识有意思合拍的人。</p></div>
		<p>「香芋星球」是一种全新的相遇方式。以双向的“一见钟情”找到和你确认过眼神的人。</p>
		<p>简单、心动、惊喜。相遇本该如此美好。</p>
		<div><p><span>《香芋星球》功能<span></p></div>
		<p>【一键喜欢】喜欢一下，立马开聊，心动不等待</p>
	  </div>	
	  <div>
	     <p> 测试数据</p>
	  </div>
	</div>
	
	<!-- 提取出的结果 -->
	”“”
	《xxxx》是一款为大家提供了超多便利交友过程的平台!
	《xxx》介绍
	单身的你，或是想寻找生命中的那个TA，或是想认识有意思合拍的人。
	「香芋星球」是一种全新的相遇方式。以双向的“一见钟情”找到和你确认过眼神的人。
	简单、心动、惊喜。相遇本该如此美好。
	《香芋星球》功能
	【一键喜欢】喜欢一下，立马开聊，心动不等待
	“”“





3、编写一个装饰器save_html, 用于保存html，装饰到 analyze_list 上。

```
@save_html
def analyze_list(html):
       # 解析html , 获得 a_list
      for a in a_list:
           yield a

url = "https://test.cn/test"
rqobj = requests.get(url)
for a in analyze_list(rqobj.text):
	print a

```

















4、  手撸一只爬虫，从好游快报抓取 <人气榜><飙升榜><期待棒> 中的游戏列表 和 游戏详细数据

<https://www.3839.com/top/hot.html>

![image-20190716195421871](/Users/weicheng/Library/Application Support/typora-user-images/image-20190716195421871.png)







- http 请求基础知识
- 数据提取，xpath,  正则表达式,  JS数据提取
- python 基础，迭代器、生成器、装饰墙。
- 实战问题，手撸一只爬虫
- 抓包，反编译







1）如何获得大量IP资源（业界主流方法）

2）如何获得账号资源，如何进行大量账号登陆

3）抓取系统如何构建，如何可扩展

4）如何探测封杀阈值

5）如何将爬虫模拟成正常用户

6）每个模块使用到的最佳工具

7）其他系统杂项trick，如何流量均衡等等

这个talk一定不能让新浪微博的老同志混进来，否则他们一定开心死了。另外百度的opencralwer的作者也将从抓取一个主流网站开始说说他们如何解决抓取过程中的问题。另外美团等公司也会派大量爬虫团队参加。

好，下面就是6个考题，都是选择题，选好后发邮件即可。

1）爬虫为什么要做DNS缓存？

A：可以节约抓取带宽

B：节约域名解析时间

C: 减少下载数据大小

D：防止多次DNS请求被抓取目标网站封杀



2）Etag干什么用的？

A：防止重复图片download

B：节约http header的大小

C：提示web服务可以接受压缩数据

D：提示网页内容的标签信息



3）Transfer-Encoding为chunked时，会出现什么情况

A：通常没有Content-Type域

B：通常没有Content-Length域

C：网页数据不可能同时即是压缩数据又是chunked数据

D：数据结尾标记是：一个数值（表示总长度）\r\n\r\n



4）tcp最小数据载荷是多少字节（抛出协议头部）？ the minimum "data" size of a TCP segment should be？

A：6字节

B：20字节

C：24字节

D：不确定



5）当最后一个包比最小数据载荷还小时，TCP/IP协议如何处理是否结束？

A：在最后一个包的末尾填充特殊字符以表示数据结束

B：最开始协商的数据大小和已经接受的数据一致即可判断结束

C：再发一个最小数据载荷大小的空包已表示数据结束

D：和具体协议实现有关，并不完全确定



6）下面那一项是爬虫工程师不需要的

A：人工智能

B：系统架构

C：网络相关

D：HTTP协议

E：浏览器

F：数据存储

G：待遇持续保持在比较低的水平





===============

1）下面哪种方式可以让爬虫合理、合法地抓取当日尽可能多的数据？

A. 通过漏洞进入他人计算机系统，把数据库dump出来。

B. 用大量低频关键词在目标站点上搜索，获得当日更全数据。

C. 找到热门的hub页，热门的话题，热门的账号，获取当日更全数据。

D. 用热门关键词在百度等搜索引擎上，用site:www.website.com + 关键词 查询，从而发现新数据

 

2）以下所列出的方法中，浏览器web数据抓取效率最高的方法是？

A. selenium + phantomjs

B. 使用chrome或者chrome内核抓取

C. 模拟web协议直接用wget或curl抓取

 

3）下面哪项是手机端抓取app数据相比web端的优势（**多选**）：

A. 手机端协议简单容易分析

B. 手机端可以使用模拟点击

C. 手机端就算出新版了旧版还是可以继续使用，不会立即停掉

D. 通常来说，手机端抓取同样信息量的数据，下载量更低

 

4）下面哪些代理支持rawsocket连接（**多选**）？

A. HTTP代理

B. HTTPS代理

C. SOCKS4代理

D. SOCKS5代理

 

5）下面代码请求实际访问地址url是什么？ 

 

url = "https://test.cn/test"

params = {

   "xxxx":"1234"

}

headers = {

   "Host": "www.test.cn",

   "Accept-Encoding": "gzip,deflate",

   "Connection": "Keep-Alive"

}

requests.get(url, params, headers =headers, allow_redirects = False, verify = False)

 

假设http://test.cn/test?xxxx=1234返回的状态码302且response header里有Location:http://www.test.cn/dpool/ttt/domain.php?d=test&xxxx=1234

 

A. https://test.cn/test

B. https://test.cn/test?xxxx=1234

C. https://www.test.cn/test?xxxx=1234

D.http://www.test.cn/dpool/ttt/domain.php?d=test&xxxx=1234

 

6）假如你要爬大量youtube视频的二进制内容，存储在本地，最佳的办法是？

A. Mysql数据库存储

B. Redis存储

C. Mongodb存储

D. 文件系统

 

7）如果想爬自己手机应用上的HTTPS的数据，获得明文，下面哪个说法是正确的？

A. 自己搭建一个HTTPS代理，让手机设置为这个代理，即可获得明文

B. 任何HTTPS明文都是可以获取的

C. 在PC上建立一个无线热点，让手机连这个热点，并使用Wireshare软件分析出HTTPS的明文数据

D. 通过让手机系统信任根证书，使用Man-in-the-middle中间人攻击技术，就可以获取任何HTTPS明文

 

8）以下哪个功能chromedriver协议不支持？

A. 注入js文件

B. 模拟鼠标滑动

C. 网络请求的响应式处理

D. 同个实例可以同时操作多个页面

 

9）爬取数据过程中，哪个情况是最不可容忍的？

A. 爬取的数据不完整，有部分数据遗失

B. 爬取程序非法关闭，内存泄露

C. 爬取的数据部分出错，手动修改

D. 不同版本的数据合并在一起

 

10）爬虫开发不会涉及到的技术或者知识有？

A. tcp，udp传输协议

B. 反汇编技术

C. 数据库存储

D. 音视频流解析

E. 网络路由协议

F. 以上都会涉及



================

\1. 使用python中的requests库时（目前版本v2.22），以下哪种说法不正确：

A. 支持自定义请求中的headers顺序

B. 支持不同域名使用不同代理

C. 支持http2

D. 支持socks代理





\2. 一般来说, python的requests.get函数会对传入的url进行urlencode操作. 但当如下代码中的keyword为哪个选项时, 无法得到预期的结果：

代码：requests.get('https://baike.baidu.com/item/{}'.format(keyword))

A. '梁斌'

B. 'C# 入门经典'

C. 'r&b'

D. '川上とも子'





\3. 如果进行大规模并发抓取（比如1000并发+，单核单进程），下面哪个python的库的效率最好的：

A. urllib

B. requests

C. http.client

D. aiohttp





\4. 使用Chrome devtools控制单个Chrome浏览器进行自动化操作时（原生chrome，且不使用插件的情况下），以下哪个说法正确的是：

A. 不能控制Chrome中的多个窗口

B. 不能抓取来自网络层的原始数据

C. 不能动态切换Chrome的代理

D. 不能禁止图片加载





\5. 以下对于Chrome headless模式的描述中，哪个是错误的？

A. headless模式的User-Agent与普通（非headless）模式是不一样的

B. headless模式是有BOM和DOM的

C. headless模式是不支持Webassembly的

D. headless模式是支持鼠标点击事件的





\6. 下列那种加密方式能最大限度抵御彩虹表的爆破：

A. HMAC-MD5

B. MD5

C. MD4

D. SHA1





\7. 现在很多app采用了证书锁定ssl pinning来防止中间人攻击，关于ssl pinning下列说法错误的是：

A. ssl pinning是将服务端证书打包内置到移动客户端中，HTTPS连接建立时与服务端返回的证书对比一致性，以确定这个连接的合法性

B. 采用ssl pinning的app，仍然可以直接使用mitm proxy，fiddler等抓包工具可获取到明文包

C. 使用frida等工具绕过证书锁定后，抓包工具才能获取到明文HTTPS数据包

D. 采用了ssl pinning证书锁定的app，内置证书一般为自签名证书





\8. 以下对xposed的描述中，正确的是：

A. xposed是对内核中init进行修改，使其能够注入到任何进程中

B. xposed不能hook native中的函数

C. xposed中的XposedBridge.jar会出现在任意apk进程的/proc/self/maps中

D. xposed并不支持Android Oreo的版本





\9. 以下哪条语句能在frida中输出2019, Pet类定义如下：



public class Pet {

​    private static int kind = 2019;

​    private static int kind()

​    {

​        return 9102;

​    }

}



A. console.log( Pet._kind );

B. console.log( Pet.kind );

C. console.log( Pet._kind.value );

D. console.log( Pet.kind.value );





\10. 关于app反调试下列说法错误的是：

A. app可以通过ptrace自身，来阻止调试器ptrace附加到app进程实现反调试

B. 在对程序脱壳过程中，经常需要将/proc/pid/mem或者/proc/pid/maps下内存数据dump出来, 可以使用inotify对文件进行监控，如果发现文件系统的的打开，读写，可能程序在被破解，就可以执行kill进程操作

C. 通过遍历程序内存段是否存在断点指令，来判断程序是否正在被调试，是则kill进程

D. 程序处于被调试状态时，某些关键指令的执行速度变化不大，所以通过对比关键代码执行的前后时间差，不能够判断出进程是否被调试





\11. 以下关于frida的使用哪项不正确？

A. java层的hook必须在java.perform中执行

B. java层同名函数的hook，可以通过不同参数数量来区分，而不用写overload

C. frida以spawn方式启动app可以hook app在启动时就执行的函数

D. frida可以更改某个native函数的实现





\12. 下面通过IDA反汇编的arm指令，其中描述不正确的是？

.text:0000ED72  MOVS            R0, R0

.text:0000ED74  POP             {R0}

.text:0000ED76  CMP             R1, #0

.text:0000ED78  BNE             loc_ED84

.text:0000ED7A  PUSH            {R0,R1,LR}

.text:0000ED7C  BL              sub_B2544

.text:0000ED80  MOVS            R6, R1

.text:0000ED82  MOVS            R0, R0



A. BL是带返回的跳转指令

B. 0xED7C位置进行的跳转后LR寄存器的值为0xED81

C. sub_B2544是程序员定义的函数名，此处将调用sub_B2544函数

D. 0xED78位置的指令含义是如果R1 != 0则进行跳转



1３. 做爬虫难，还是做反爬难？

发表下您的看法，并简单阐述下原因（100字以内，开放式题目，没有对错，可自由发挥）。



// 获取节点下的所有文本

````


selector.xpath("//section[3]/div/div/div[2]//text()").extract()

selector.xpath("//section[3]/div/div/div[2]").xpath('string(.)').extract_first()

````

