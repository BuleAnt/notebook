#### 复习整理



>  MapReduce、Hdfs、Yarn等 Hadoop核心及运行机制，集群调优 

##### MapReduce

一种并行处理数据的编程模型，被称为job, 是客户端需要执行的一个工作单元。

- 结构：

  map 和 reduce两个阶段构成，每个阶段都以键-值对作为输入和输出

- job, task, input split
- shuffle : map 任务 和 reduce 任务直接的数据流
- combiner

**特点**

- 易于编程
- 良好的扩张性
- 高容错性
- 海量数据的离线处理

不擅长

- 实时计算
- 流式计算
- DAG计算（作业流图）



##### HDFS

- 组成结构：

  1 Master(NameNode / NN)  带 N个SLaves(DataNode / DN)

  1个文件会被拆分成多个Block

  

  **NN**：

  1）负责客户端请求的响应

  2）负责元数据(文件的名称、副本系数、Block存放的DN位置) 的管理

  3）记录文件的修改记录

  >NameNodes维护HDFS的名称空间树以及文件块到存储数据的DataNodes的映射。一个简单的HDFS集群只能有一个主NameNode，由一个辅助NameNode支持，它定期压缩包含HDFS元数据修改列表的NameNode编辑日志文件。这样可以减少NameNode上日志文件占用的磁盘空间量，从而减少主NameNode的重启时间。甲[高可用性](https://www.cloudera.com/documentation/enterprise/5-7-x/topics/admin_ha.html#concept_bry_nzg_nj)集群包含两个NameNodes：活动和备用。

  **DN**：

  1）存储用户的文件对应的数据块（Block）

  2) 要定期向NN发送心跳信息，汇报本身及其所有的block 信息，健康状况


​        

        #### 	JournalNodes:

​	高可用性群集使用JournalNodes同步活动和备用NameNode。活动NameNode通过对HDFS命名空间元数据的更改或“编辑”向每个JournalNode写入。在故障转移期间，备用NameNode会在将其自身升级为活动状态之前应用JournalNodes中的所有编辑。

>CDH默认块大小（dfs.blocksize）设置为128 MB。NameNode上的每个名称空间对象消耗大约150个字节。
>
>Cloudera Manager为每百万个块（但不小于1 GB）分配1 GB的最大堆空间。





​	**HDFS 优点**

 	高容错, 适合批处理, 适合大数据, 构建中廉价的机器上

​	**HDFS 缺点**

​	低延迟的数据访问,小文件存储

```
etc/hadoop/conf/hadoop-env.sh
# 设置 Hadoop项目服务器（如HDFS，YARN和MapReduce）设置JVM堆大小
# HADOOP_HEAPSIZE是作为最大内存（Xmx）参数传递给JVM的整数
HADOOP_HEAPSIZE = 1024

# HADOOP_NAMENODE_OPTS特定于NameNode并设置必须指定的所有JVM标志。HADOOP_NAMENODE_OPTS会覆盖NameNode 的HADOOP_HEAPSIZE Xmx值。例如

ADOOP_NAMENODE_OPTS = -Xms1024m -Xmx1024m -XX：+ UseParNewGC -XX：+ UseConcMarkSweepGC -XX：CMSInitiatingOccupancyFraction = 70 -XX：+ CMSParallelRemarkEnabled -XX：+ PrintTenuringDistribution -XX：OnOutOfMemoryError = {{AGENT_COMMON_DIR}} / killparent.sh
```



#### yarn

MapReduce1.x 存在的问题

jobTracker 负责资源调度 和 任务调度，

taskTracker 负责干活

- 资源利用率 & 运维成本 & 多套集群
- jobTracker 太忙碌

YARN

- 基于资源配置，多种组件使用 调度，共享资源

**YARN 架构**

1 RM(ResourceManager) + N NM(NodeManager)

**ResourceManager的职责**： 一个集群active状态的RM 只有一个, 负责整个集群的资源管理和调度

1) 处理客户端的请求(启动/杀死任务)

2) 启动/监控 ApplicationMater(一个作业对应一个AM)

3) 监控NM

4) 系统的资源分配和调度



**NodeManager** 职责：整个集群中有N个， 负责单个节点的资源管理和使用以及task的运行情况

1) 定期向RM汇报本节点的资源使用情况 和 各个Container的运行状态

2) 接收并处理RM 的container 启动/停止的各种命令

3) 单个节点的资源管理和任务管理



**ApplicationMater** 职责：每个应用/作业对应一个，负责应用程序的管理

1)  数据切分

2) 为应用程序向RM申请资源( container), 并分配给内部任务ß

3) 与NM通信以启动/停止task, task 是运行在container中的

4) task 的监控和容错



**Container**

 对任务运行情况的描述：CPU、memory、环境变量



**YARN 执行流程**

1)  用户向YARN 提交作业

2) RM 为该作业分配一个container(AM)

3) RM 会与对应的NM通信, 要求NM 在这个container上启动应用程序的AM

4) AM首先向RM 注册，然后AM将为各个任务申请资源，并监控运行情况

5) AM采用轮询的方式通过RPC协议向RM申请和领取资源

6) AM申请到资源后，便和相应的NM通信，要求NM启动任务

7) NM启动我们作业对应的task

#### MapReduce的工作机制
pass




#### Hadoop  调优

- 增加同时打开的文件描述符和网络连接上限，作业数量的增加，文件的读写与网络连接操作可能会因为资源不够而失败

- 关闭SWAP分区，分区置换，导致相应变慢
- 设置合理的预读取缓冲区大小，使用blockdev命令，64KB
- 调整心跳设置，集群小于300时，心跳间隔为300毫秒，每增加一百台，则增加一秒
- 磁盘配置为多磁盘，可以缓解压力
- 配置机架感知
- 开启任务推测执行，
- 操作系统调优，从应用程序角度进行优化
- Hadoop参数调优，
- https://www.2cto.com/net/201805/746039.html



> Hive的日常查询、分区分桶、开窗、自定义函数等，且有hql的优化经验

#### 托管表、外部表
托管表：hive 将数据已入它的仓库目录，删除表时, 将表结构和数据一起删除 
外部表：让hive 到仓库外的位置访问数据，删除表时，只删除表结构

#### 分区表

分区表指的是在创建表时根据分区列的值，把表组织成分区，指定的partition的分区空间，物理上是一个文件夹

表和分区可以进一步分为桶，它会为数据提供额外的结构以获取更高效的查询处理。基于ID分桶。

分区/分桶 优点：
- 对于限制到某个特征的查询，会变的非常高效，只需要扫描查询范围内的分区中的文件
- 连接两个在（包含连接列的）相同列上划分了桶的表，可以使用（map-side join）高效的实现
- 采样更高效, 可以进排序

使用 CLUSTERED BY 子句指定划分桶所用的列和要划分的桶的个数
```
CREATE TABLE bucketed_users (id INI, name STRING)
CLUSTERD BY (id) INTO 4 BUCKETS;
```

#### 存储格式
- 行格式
- 文件格式

#### 自定义函数 UDF 和 UDAF

UDF：
- UDF 操作作用于单个数据行，且产生一个数据行作为输出，多数数学函数和字符串函数都是这类
- UDAF 接受多个输入数据行，并产生一个输出数据行
- UDTF 作用于单个数据行，且产生多个数据行作为输出

#### 开窗函数
普通的聚合函数聚合的行集是组,开窗函数聚合的行集是窗口。因此,普通的聚合函数每组(Group by)只返回一个值，而开窗函数则可为窗口中的每行都返回一个值。简单理解，就是对查询的结果多出一列，这一列可以是聚合值，也可以是排序值。
开窗函数一般分为两类,聚合开窗函数和排序开窗函数。

**聚合开窗函数**
- count开窗函数
- sum开窗函数
- min开窗函数
- max开窗函数
- avg开窗函数
- first_value开窗函数
- last_value开窗函数
- lag开窗函数
- lead开窗函数
- cume_dist开窗函数

**排序开窗函数**
- rank开窗函数
- dense_rank开窗函数
- ntile开窗函数
- row_number开窗函数
- percent_rank开窗函数

#### 调优
https://www.cnblogs.com/smartloli/p/4356660.html


> Hbase日常查询，和api操作，[了解Hbase的读写流程原理、存储原理、wal机制、compact机制、 scanner 体系、hfile 格式、协处理器、布隆过滤器、预分区、rowkey 设计等。] 

#### hbase 查询

> Flume进行数据传输，多层拓扑实现负载均衡和容灾，自定义拦截器、数据监控等。

#### Fluem 的结构


> Kafka传输数据，了解集群间消息复制和同步机制，存储机制，生产消费流程，高低级api区别，分 区机制及自定义分区方式等.

#### kafka

> 用Sparkcore、Sparksql、Sparkstreaming等，了解Spark部署模式、通信架构、任务调度机制、 shuffle 过程、内存管理机制、核心组件，性能调优。 

#### spark


> Zookeeper协调调度各个框架，理解Zookeeper存储和通知机制。 熟练使用Azkaban调度任务，熟练使用Sqoop导入导出数据。

#### zookeeper







