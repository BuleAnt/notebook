# 整体爬虫工程：基础设施现行方案和机制

[![User icon](https://zaoshu.atlassian.net/wiki/aa-avatar/85bf7fe45f774b79895b644a1535458f?s=48&d=https%3A%2F%2Fzaoshu.atlassian.net%2Fwiki%2Fimages%2Ficons%2Fprofilepics%2Fdefault.png%3FnoRedirect%3Dtrue)](https://zaoshu.atlassian.net/wiki/display/~qiandengsheng)

[钱登胜](https://zaoshu.atlassian.net/wiki/display/~qiandengsheng)

Yesterday at 11:46 AM

## 背景

### 目前爬虫项目分类

- 独立scrapy项目
  - 使用scrapy框架编写的爬虫项目
  - 当前运行情况为：
    - 一个scrapy容器，运行scrapy爬虫和scrapyd服务
    - 一个专属的spiderkeeper容器
    - 视情况可能会有一个专属的redis容器
- 特殊爬虫项目
  - 需要特定逻辑持续交互的爬虫项目
  - 举例：yy爬虫
- 分布式爬虫、分组爬虫项目
  - 运行于京东容器云的爬虫项目
  - 整体代码限制在一个Github代码仓库范围内
    - 可以构建出一个或多个镜像
    - 整体镜像组由代码构建的镜像和依赖的外部镜像（例如redis）构成
    - 运行时每种镜像可以有零到多个运行实例，可以有不同的配置和参数
    - 所有容器实例需要协调同时运行，各自需要较高的计算资源和隔离性，对网络带宽要求一般

### 目前计算环境

- 阿里云
- 京东云
- 京东容器云

### 目前数据库方案

- 单实例MongoDB

## 基础设施

### 数据库

- 多实例隔离
  - 以负载压力、数据压力、用途等为依据，所有项目分散在多个数据库实例内
  - 测试环境和生产环境隔离
- 数据库备份
  - 每天凌晨定时备份数据库磁盘，每个副本保留10天
- 数据库归档
  - 针对数据量极大的数据库，会在磁盘容量达到60%阈值时，执行相关旧数据归档操作
- 权限控制
  - 密码保护
    - 使用MongoDB的basic auth，没有使用SSL/TLS保护
      - 根据官方文档，basic auth使用的两种方案都可以在每次通讯时根据用户密码使用不一样的通讯密码，且没有任何可能在网络上传输用户密码
      - 不使用SSL/TLS可以简化服务端配置和客户端程序配置，避免性能影响
      - 目前做的这个权限理论安全性可以接受
    - 每个数据库的用户都不同，各自密码长度为30位及以上的随机大小写字母数字序列
  - 默认情况下在某个数据库实例上创建数据库后，为该数据库生成三个用户
    - read
      - 仅有读取权限，一般提供给开发人员查看数据使用
    - write
      - 有读写权限，移除了dropCollection等危险操作权限，一般写入部署工具的配置中，仅程序使用
    - owner
      - 拥有该数据库的完整权限，特殊情况下可以申请使用，需要开发人员和相关负责人同时监督
      - 场景：collection的大规模移动等操作
  - 内外网控制
    - MongoDB数据库服务器同时监听在内外网的某个端口上
    - 所有同一子网下的爬虫一律使用内网地址访问数据库，避免性能和流量问题
    - 所有对数据库有大流量读写的操作，都强烈建议在内网执行或联系管理员
      - 举例：dump/restore数据，一般未压缩数据量在2GB以上时，都需要考虑内网执行

### 部署工具

- CircleCI
  - CircleCI可以查看项目构建情况，权限等同于Github权限
  - Release项目的构建需要通知相关管理人员确认，一般情况下仅有代码仓库的读写权限的人员无法看到release项目的真实构建状态
- Deployer
  - 阿里云环境内的容器部署工具
  - 京东容器云环境内的独立容器、集群容器、分组容器的部署工具

### 项目管理工具

- SpiderKeeper
  - 搭配爬虫容器内的Scrapyd，实现爬虫状态的控制和查看、定时任务的设置等功能
  - 即将移除
- Airflow
  - 综合功能：爬虫运行流程管理、实时状态检查、最终状态检查、定时任务配置和运行、消息通知
  - 开发中

### 监控工具

- 阿里云基础监控
  - 管理人员负责
- Registrator容器基础状态监控
  - 管理人员负责
- SpiderNotification爬虫状态监控
  - 通知到具体负责人
- Prometheus监控工具
  - 用于具体容器性能分析等用途
  - 其他配套工具：cAdvisor，NodeExporter

### 代码管理

- 使用公司的Github私有仓库管理所有代码

### 访问控制

- jumpserver
  - 单独签发一套证书，用于访问授权虚拟机
- wormhole
  - 单独签发一套证书，用于端口转发

### 运行环境

- 容器化项目
  - 一般情况下，所有的项目进入测试环境和生产环境时，都是容器化的形式
- 虚机项目
  - 目前有部分项目运行在虚机环境中，考虑到已长期成熟稳定运行、迁移成本等因素，维持现状

### 计算&存储&网络

- 计算
  - 阿里云虚机环境下，提供整机性能
  - 阿里云容器环境下，理论上为单个容器提供2c2g性能，考虑到多个容器公用一个机器的情况，实际情况可能有较大差异
- 存储
  - 阿里云虚机环境下，按需提供磁盘
  - 阿里云容器环境下，考虑到数据库和日志全部外置，一般不提供存储能力，容器内整体运行大小限制一般在4GB左右
- 网络
  - 带宽在0~100Mbps不等，按量计费，入网流量不收费，一般只需要关注出外网的流量

### 日志系统

- EFK
  - 综合收集所有日志的基础设施
  - 需要使用与wormhole一致的证书访问Kibana

### 其他

- redis
  - 每个项目独立一个redis容器实例，一般情况下仅允许内网访问
  - 提供的理论性能：1核心，256MB内存
  - 注意事项：不建议将大量数据放入redis，如果出现这种情况，应该考虑修改代码逻辑
- pypi-server
  - 内部python包管理服务，需要证书访问 ，一般内置于基础镜像中
- registry
  - 自建的docker registry，提供镜像相关的管理服务

## 测试环境

- 目前线上测试环境为公用环境，机器性能配置为2核心4GB内存
- 所有项目进入生产环境前都应该进入测试环境执行测试并确认可靠
- 一般在快速测试完成后应当及时关闭爬虫或容器，不建议在测试环境内长时间运行大量数据爬取
  - develop分支的代码每次发生变动后会触发自动构建，并部署至测试环境，需要注意这一点